{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5qrBDufBYc3",
        "colab_type": "code",
        "outputId": "ba931222-6fdc-47e5-86a6-0b4067e225cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install torchtext==0.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.4 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.18.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4) (2019.11.28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvsit6RfYyid",
        "colab_type": "text"
      },
      "source": [
        "The AG_NEWS dataset consists of 4 types of news articles (World, sports, business, sci/tech). 120K train samples and 76K test samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLwsVpljXq4a",
        "colab_type": "code",
        "outputId": "6f1709b8-79e4-4155-fa64-a31155cff3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "import os\n",
        "if not os.path.isdir('./.data'):\n",
        "  os.mkdir('./.data')\n",
        "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data',ngrams=2,vocab=None)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE=16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000lines [00:06, 18333.38lines/s]\n",
            "120000lines [00:13, 8919.15lines/s]\n",
            "7600lines [00:00, 9705.19lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZv9vIPaS1-",
        "colab_type": "text"
      },
      "source": [
        "The dataset is in a TorchText object. We can query properties using inbuilt routines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XanVULvpafQ8",
        "colab_type": "code",
        "outputId": "77fb4030-affc-403e-cd91-e545f2a81fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(train_dataset.get_vocab())\n",
        "num_class = len(train_dataset.get_labels())\n",
        "print(vocab_size, num_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1308844 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HExHC0K3mepZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ag_news_label = {0 : \"World\",\n",
        "                 1 : \"Sports\",\n",
        "                 2 : \"Business\",\n",
        "                 3 : \"Tech\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj_CTW-rda0u",
        "colab_type": "text"
      },
      "source": [
        "We need to write a method to get batches of data from this object. We collect bunch of text sequences (of variable length). Since lengths are variable, we store a tensor of delimiters ('offsets') to denote beginning of each sequence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvCH0uOrdhOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "  labels = torch.tensor([entry[0] for entry in batch])\n",
        "  text = [entry[1] for entry in batch]\n",
        "  offsets = [0] + [len(entry) for entry in text]\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  text = torch.cat(text)\n",
        "  return text, offsets, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9TC67wdZQoz",
        "colab_type": "text"
      },
      "source": [
        "Let's train a simple language model to predict the type of news article. We will use an \"embeddingbag\" layer which converts words/2-grams to vectors, and then classify using a linear fully connected layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk-eXedObomJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TextSentiment(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim,num_class):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.EmbeddingBag(vocab_size,embed_dim,sparse=True)\n",
        "    self.fc = nn.Linear(embed_dim,num_class)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.embedding.weight.data.uniform_(-initrange,initrange)\n",
        "    self.fc.weight.data.uniform_(-initrange,initrange)\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  def forward(self,text,offsets):\n",
        "    embedded = self.embedding(text,offsets)\n",
        "    return self.fc(embedded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2wtfRebfRTx",
        "colab_type": "text"
      },
      "source": [
        "OK, now let's write a simple data loader and routine to train/test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9OakDAIfUHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "embed_dim = 32\n",
        "model = TextSentiment(vocab_size,embed_dim,num_class).to(device)\n",
        "\n",
        "def train_func(sub_train):\n",
        "  train_loss = 0\n",
        "  train_acc = 0\n",
        "  data = DataLoader(sub_train,batch_size=BATCH_SIZE,shuffle=True,collate_fn=generate_batch)\n",
        "  for i, (text,offsets,labels) in enumerate(data):\n",
        "    optimizer.zero_grad()\n",
        "    text,offsets,labels = text.to(device),offsets.to(device),labels.to(device)\n",
        "    output = model(text,offsets)\n",
        "    loss = criterion(output,labels)\n",
        "    train_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc += (output.argmax(1)==labels).sum().item()\n",
        "\n",
        "  scheduler.step() #adjust learning rate\n",
        "\n",
        "  return train_loss/len(sub_train), train_acc/len(sub_train)\n",
        "\n",
        "def test_func(sub_test):\n",
        "  test_loss = 0\n",
        "  test_acc = 0\n",
        "  data = DataLoader(sub_test,batch_size=BATCH_SIZE,collate_fn=generate_batch)\n",
        "  for i, (text,offsets,labels) in enumerate(data):\n",
        "    text,offsets,labels = text.to(device),offsets.to(device),labels.to(device)\n",
        "    with torch.no_grad():\n",
        "      output = model(text,offsets)\n",
        "      loss = criterion(output,labels)\n",
        "      test_loss += loss.item()\n",
        "      test_acc += (output.argmax(1)==labels).sum().item()\n",
        "  \n",
        "  return test_loss/len(sub_test), test_acc/len(sub_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSwPy9hUieVP",
        "colab_type": "code",
        "outputId": "648698ae-8413-41a9-ecbd-3e68d3a03ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "num_epochs = 5\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,1,gamma=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  %time train_loss, train_acc = train_func(train_dataset)\n",
        "\n",
        "  print('Epoch = %d' %(epoch+1))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.8 s, sys: 482 ms, total: 8.28 s\n",
            "Wall time: 8.36 s\n",
            "Epoch = 1\n",
            "\tLoss: 0.0259(train)\t|\tAcc: 84.8%(train)\n",
            "CPU times: user 7.77 s, sys: 456 ms, total: 8.23 s\n",
            "Wall time: 8.31 s\n",
            "Epoch = 2\n",
            "\tLoss: 0.0118(train)\t|\tAcc: 93.7%(train)\n",
            "CPU times: user 7.72 s, sys: 464 ms, total: 8.19 s\n",
            "Wall time: 8.24 s\n",
            "Epoch = 3\n",
            "\tLoss: 0.0070(train)\t|\tAcc: 96.3%(train)\n",
            "CPU times: user 7.74 s, sys: 467 ms, total: 8.21 s\n",
            "Wall time: 8.27 s\n",
            "Epoch = 4\n",
            "\tLoss: 0.0040(train)\t|\tAcc: 98.0%(train)\n",
            "CPU times: user 7.93 s, sys: 426 ms, total: 8.36 s\n",
            "Wall time: 8.48 s\n",
            "Epoch = 5\n",
            "\tLoss: 0.0023(train)\t|\tAcc: 99.0%(train)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQOk_Ag7lqha",
        "colab_type": "code",
        "outputId": "6c92f21c-b16a-4bc4-9fa7-4c4bd8e00126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "%time test_loss, test_acc = test_func(test_dataset)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 201 ms, sys: 4.6 ms, total: 206 ms\n",
            "Wall time: 207 ms\n",
            "\tLoss: 0.0238(test)\t|\tAcc: 90.3%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyQ8dlPPmLdF",
        "colab_type": "text"
      },
      "source": [
        "Cool! Let us now see if we can test it on a real world example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F8lyudxnE2U",
        "colab_type": "code",
        "outputId": "f3d6d42f-42f2-49f3-b203-c80e9a449dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "def predict(text,model,vocab,ngrams):\n",
        "  tk = get_tokenizer('basic_english')\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor([vocab[token] for token in ngrams_iterator(tk(text),ngrams)])\n",
        "    output = model(text,torch.tensor([0]))\n",
        "    return output.argmax(1).item()\n",
        "  \n",
        "ex_string = \"\"\"The worldâ€™s airlines, no longer operating a globe-spanning choreography of flights, \n",
        "  are consumed with new work: navigating government bailout offers, negotiating with unions,\n",
        "  finding places to park idle planes and scrounging for business like flying cargo \n",
        "  and repatriating marooned travelers.\"\"\"\n",
        "\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to('cpu')\n",
        "print('%s' %ag_news_label[predict(ex_string,model,vocab,2)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Business\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}